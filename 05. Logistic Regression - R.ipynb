{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Exercise 5 - Logistic Regression\n===\n\nSimple logistic regression predicts binary (yes/no) events. For example, we may want to predict if someone will arrive at work on time, or if a person shopping will buy a product. \n\nThis exercise will demonstrate simple logistic regression: predicting an outcome from only one feature.\n\n#### Run the code below to prepare the necessary libraries for this exercise."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run this!\n\nsuppressMessages(install.packages(\"tidyverse\"))\nsuppressMessages(library(\"tidyverse\"))\nsuppressMessages(library(\"glmnet\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "Step 1\n---\n\nWe want to place a bet on the outcome of the next football (soccer) match. It is the final of a competition, so there will not be a draw. We have historical data about our favourite team playing in matches such as this. \n\nComplete the exercise below to see the structure of this data.\n\n### In the cell below replace:\n#### 1. `<dataPreviewStr>` with `str`\n#### 2. `<dataPreviewHead>` with `head`\n#### then __run the code__."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "team_stats <- read.delim(\"Data/football data.txt\")\n\n###\n# REPLACE <dataPreviewStr> WITH str AND <dataPreviewHead> WITH head\n###\n<dataPreviewStr>(team_stats)\n<dataPreviewHead>(team_stats)\n###\n\nsummary(team_stats$average_goals_per_match)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The `team_stats` data shows the average goals per match of our team for the season in the first column, and whether the team won the competition in the second column. The `won_competition` variable is a binary outcome, where 1 represents a win, and 0 represents a loss.\n\nStep 2\n---\n\nLet's graph the data so we have a better idea of what's going on. \n\nComplete the exercise below to make a scatter plot of `team_stats`. Replace the x variable with the names of the feature we want to plot on the x-axis.\n\n#### In the cell below replace `<xData>` with `average_goals_per_match`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "team_stats  %>% \n###\n# REPLACE <xData> WITH average_goals_per_match\n###\nggplot(aes(x = <xData>, y = as.factor(won_competition), colour = as.factor(won_competition))) +\n###\n\ngeom_jitter() +\nggtitle(\"Game statistics for favourite football team\") +\nxlab(\"Average number of goals scored per match\") +\nylab(\"Competition win\") +\n# Align title to centre\ntheme(plot.title = element_text(hjust = 0.5), legend.position = \"none\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the plot above, we have used ggplot2's `geom_jitter` function, which adds a small amount of random variation to the location of each point. Since we have binary outcomes in this dataset, using this function allows us to handle overplotting.\n\n> If you want to test this for yourself, change the `geom_jitter` call in the code block above to `geom_point`; it is harder to decipher which points overlap using the latter function.\n\nWe can see that in general, when our team has a good score average (x-axis), they tend to win the competition.\n\nStep 3\n---\n\nHow can we predict whether the team will win this season? Let's apply AI to this problem, by making a logisitic regression model using this data and then graphing it.\n\nWe will use the function `glm`, which stands for generalized linear models. We will set the type of model (\"family\" argument) as binomial logistic regression - to specify that we want a logistic regression model. \n\nWe'll use the standard R format for the formula, which is `labels ~ features` (if you see a `.` this means it will select all features in the dataset).\n\n### In the cell below replace:\n#### 1. `<formula>` with `won_competition ~ average_goals_per_match`\n#### 2. `<dataset>` with `team_stats`\n#### then __run the code__."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###\n# REPLACE <formula> WITH won_competition ~ average_goals_per_match AND <dataset> WITH team_stats\n###\nglm_team <- glm(formula = <formula>, family = binomial(link = \"logit\"), \n                data = <dataset>)\n###\nsummary(glm_team)\n\n# And we'll quickly print out some predictions to make sure it's working\nhead(predict(glm_team, data = team_stats, type = \"response\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Alright, that's the model done. Now run the code below to graph it."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run this!\n\n# Plot using ggplot2\nteam_stats %>%\nggplot(aes(x = average_goals_per_match, y = won_competition)) +\ngeom_point(aes(colour = as.factor(won_competition)), alpha = 0.5, size = 3) +\ngeom_smooth(method = \"glm\", se = FALSE, method.args = list(family = \"binomial\"), \n            colour = \"black\") +\nggtitle(\"Binomial logistic regression model for football team competition win\") +\nxlab(\"Average number of goals scored per match\") +\nylab(\"Competition win\") +\ntheme(plot.title = element_text(hjust = 0.5), legend.position = \"none\") + \nscale_y_continuous(labels = c(\"0\", \"\", \"\", \"\", \"1\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We now have a binomial logistic regression model to fit our data. The black line represents our model.\n\nStep 4\n------\n\nWe can read the model above like so:\n* Take the average number of goals per match for the current year. Let's say it is 2.5.\n* Find 2.5 on the x-axis. \n* What value (on the y axis) does the line have at x = 2.5?\n* If this value is above 0.5, then the model predcits that our team will win this year. If it is less than 0.5, it predicts that our team will lose.\n\nBecause this line is just a mathematical function (equation) we don't have to do this visually.\n\nIn the exercise below, choose the number of goals you want to evaluate.\n\nThe code will calculate the probability that our team will win with your chosen number of goals in the match.\n\n#### Replace `<numberOfGoals>` with a number between 0 and 3, then run the code."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###\n# REPLACE <numberOfGoals> WITH A NUMBER BETWEEN 0 AND 3\n###\ngoals <- <numberOfGoals>\n###\n\n# Create data frame for input to predict function\nmean_goals <- data.frame(average_goals_per_match = c(goals))\n\n# Run predict function based on inout to goals\nmean_goals$prediction <- predict(object = glm_team, newdata = mean_goals, type = \"response\")\n\n# View result\nmean_goals\n\n# Print out the result to screen\npaste0(\"The probability of our team winning this year is \", round(mean_goals$prediction * 100, digits = 4), \"%\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now let's plot our chosen number of goals in the context of our model using ggplot2:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run this!\n\nteam_stats %>% \nggplot(aes(x = average_goals_per_match, y = won_competition)) +\ngeom_point(aes(colour = as.factor(won_competition)), alpha = 0.5, size = 3) +\ngeom_point(data = mean_goals, aes(x = average_goals_per_match, y = prediction), size = 5, colour = \"black\",\n           shape = \"cross\") +\ngeom_smooth(method = \"glm\", se = FALSE, method.args = list(family = \"binomial\"), \n            colour = \"black\") +\nggtitle(\"Binomial logistic regression model for football team competition win\") +\nxlab(\"Average number of goals scored per match\") +\nylab(\"Competition win\") +\ntheme(plot.title = element_text(hjust = 0.5), legend.position = \"none\") +\ngeom_hline(yintercept = mean_goals$prediction, linetype = \"dotted\") +\ngeom_vline(xintercept = mean_goals$average_goals_per_match, linetype = \"dotted\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Conclusion\n-----\n\nWell done! We have calculated the likelihood that our team will win this year's competition.\n\nYou can go back to the course now and click __'Next Step'__."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "r",
      "display_name": "R",
      "language": "R"
    },
    "language_info": {
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.4.1",
      "file_extension": ".r",
      "codemirror_mode": "r"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}